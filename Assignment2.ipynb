{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvigâ€™s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MoQeEsZvHvvi"
      },
      "outputs": [],
      "source": [
        "bigrams = pd.read_csv(\"./data/bigrams.txt\", sep=\"\\t\", encoding='latin-1', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0\n",
              "1    4\n",
              "2    3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigrams.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigrams.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>275</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>a</td>\n",
              "      <td>aaa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>a</td>\n",
              "      <td>all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>a</td>\n",
              "      <td>an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>192</td>\n",
              "      <td>a</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0  1    2\n",
              "0  275  a    a\n",
              "1   31  a  aaa\n",
              "2   29  a  all\n",
              "3   45  a   an\n",
              "4  192  a  and"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigrams.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating vocabulary dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigram_dict = dict()\n",
        "vocabulary = dict()\n",
        "\n",
        "for index, row in bigrams.iterrows():\n",
        "    key = (row[1], row[2])\n",
        "    bigram_dict[key] = row[0]\n",
        "\n",
        "    if (row[1] in vocabulary):\n",
        "        vocabulary[row[1]] += 1\n",
        "    else:\n",
        "        vocabulary[row[1]] = 1\n",
        "\n",
        "    if (row[2] in vocabulary):\n",
        "        vocabulary[row[2]] += 1\n",
        "    else:\n",
        "        vocabulary[row[2]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install editdistance -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import editdistance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_editdistance(target_word, max_distance):\n",
        "    # Initialize with target_word if it's in the vocabulary\n",
        "    possible_matches = {target_word} if target_word in vocabulary else set()\n",
        "\n",
        "    # Start searching at the next distance level\n",
        "    distance = 1\n",
        "\n",
        "    # Expand search until possible matches are found or max_distance is reached\n",
        "    while not possible_matches and distance <= max_distance:\n",
        "        for word in vocabulary:\n",
        "            if editdistance.eval(target_word, word) == distance:\n",
        "                possible_matches.add(word)\n",
        "        distance += 1\n",
        "\n",
        "    # Return the original word if no matches found within the edit distance\n",
        "    return possible_matches if possible_matches else {target_word}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_unigram(target_word, edit_distance):\n",
        "    # Find candidate words within the specified edit distance\n",
        "    candidates = best_editdistance(target_word, edit_distance)\n",
        "    \n",
        "    # Calculate the unigram probability of each candidate\n",
        "    total_vocabulary_size = len(vocabulary)\n",
        "    suggestions = [(candidate, vocabulary[candidate] / total_vocabulary_size) \n",
        "                   for candidate in candidates if candidate in vocabulary]\n",
        "\n",
        "    # Sort the suggestions based on probability, in descending order\n",
        "    return sorted(suggestions, key=lambda suggestion: suggestion[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_bigram(bigram, edit_distance, left=True):\n",
        "    # Find candidate words within the specified edit distance for the targeted part of the bigram\n",
        "    target_word = bigram[0] if left else bigram[1]\n",
        "    word_candidates = best_editdistance(target_word, edit_distance)\n",
        "\n",
        "    # Generate candidate bigrams by pairing each candidate word with the fixed part of the original bigram\n",
        "    candidate_bigrams = {(word, bigram[1]) if left else (bigram[0], word) for word in word_candidates}\n",
        "\n",
        "    # Filter and rank candidate bigrams based on their probability in bigram_dict\n",
        "    total_bigrams = len(bigram_dict)\n",
        "    suggestions = [(c, bigram_dict[c] / total_bigrams) for c in candidate_bigrams if c in bigram_dict]\n",
        "\n",
        "    # Return the suggestions sorted by probability in descending order\n",
        "    return sorted(suggestions, key=lambda x: x[1], reverse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correct_sentence(sentence):\n",
        "    words = sentence.lower().split()\n",
        "\n",
        "    if not words:  # If the sentence is empty or only contains whitespace\n",
        "        return \"\"\n",
        "\n",
        "    corrected_sentence = []\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        right_suggestions = []\n",
        "        left_suggestions = []\n",
        "\n",
        "        if i > 0:  # Look for suggestions based on the word to the left\n",
        "            right_suggestions = best_bigram((words[i - 1], word), 1, left=False)\n",
        "            right_suggestions = [(w, p) for ((_, w), p) in right_suggestions]\n",
        "\n",
        "        if i < len(words) - 1:  # Look for suggestions based on the word to the right\n",
        "            left_suggestions = best_bigram((word, words[i + 1]), 1, left=True)\n",
        "            left_suggestions = [(w, p) for ((w, _), p) in left_suggestions]\n",
        "\n",
        "        suggestions = left_suggestions + right_suggestions\n",
        "        known_word = word in vocabulary\n",
        "\n",
        "        # If no suggestions and the word is not known, try unigram suggestions\n",
        "        if not suggestions and not known_word:\n",
        "            suggestions = best_unigram(word, 1)\n",
        "\n",
        "        # Combine probabilities for the same word across different suggestions\n",
        "        probs = {}\n",
        "        for w, p in suggestions:\n",
        "            probs[w] = probs.get(w, 0) + p\n",
        "\n",
        "        # Filter tiny probabilities, adjusting threshold based on known word\n",
        "        threshold = 1e-5 if known_word else 1e-13\n",
        "        probs = {w: p for w, p in probs.items() if p > threshold}\n",
        "\n",
        "        # Choose the best suggestion or keep the original word\n",
        "        corrected_word = max(probs, key=probs.get) if probs else word\n",
        "        corrected_sentence.append(corrected_word)\n",
        "\n",
        "    return \" \".join(corrected_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def formatted_output_correction(sentence):\n",
        "    print(f'Before: \\t{sentence}')\n",
        "    print(f'After:  \\t{correct_sentence(sentence)}')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before: \tdking sport\n",
            "After:  \tdoing sport\n",
            "\n",
            "Before: \tdking patient\n",
            "After:  \tdying patient\n",
            "\n",
            "Before: \the is able to cok great food\n",
            "After:  \the is able to cook great food\n",
            "\n",
            "Before: \ti like cokking crystal mth\n",
            "After:  \ti like cooking crystal meth\n",
            "\n",
            "Before: \ti lke solvng mth prblems\n",
            "After:  \ti like solving math problems\n",
            "\n",
            "Before: \tShe excels in playing the pano\n",
            "After:  \tshe excels in playing the piano\n",
            "\n"
          ]
        }
      ],
      "source": [
        "formatted_output_correction(\"dking sport\")\n",
        "formatted_output_correction(\"dking patient\")\n",
        "formatted_output_correction(\"he is able to cok great food\")\n",
        "formatted_output_correction(\"i like cokking crystal mth\")\n",
        "formatted_output_correction(\"i lke solvng mth prblems\")\n",
        "formatted_output_correction(\"She excels in playing the pano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "- I am not an expert in NLP, so I decided to keep it simple.\n",
        "\n",
        "- My approach uses bigrams, where word, which is taken into consideration about correction is looked with bigrams from both sides. It helps to grab twice more context (we are looking for 2 nearby words, not just 1). Also it helps to prevent situations where we have a chain of corrections after changing the first word.\n",
        "\n",
        "- I use edit distance to find similar words for candidates and probability of unigram or bigram appearing in the vocabulary for the final choice.\n",
        "\n",
        "- I use thresholds for replacing known and not known words, so correction would not always trigger. For known words the threshold is set for 1e-5 and for unknown for 1e-13. It is reasonable because we often do not want to change words, which are written correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "w1 = 'hello'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Function to generate misspelled word\n",
        "def generate_misspelled_word(word):\n",
        "    choice = random.choice([\"insert\", \"replace\", \"delete\"])\n",
        "    modified_word = list(word)\n",
        "\n",
        "    if choice == \"insert\":\n",
        "        # Insert a random symbol at a random position\n",
        "        symbol = random.choice('qwertyuiopasdfghjklzxcvbnm')\n",
        "        position = random.randint(0, len(modified_word))\n",
        "        modified_word.insert(position, symbol)\n",
        "    elif choice == \"replace\":\n",
        "        # Replace a random character with a random symbol\n",
        "        position = random.randint(0, len(modified_word) - 1)\n",
        "        symbol = random.choice('qwertyuiopasdfghjklzxcvbnm')\n",
        "        modified_word[position] = symbol\n",
        "    elif choice == \"delete\":\n",
        "        # Delete a random symbol\n",
        "        if len(modified_word) > 1:\n",
        "            position = random.randint(0, len(modified_word) - 1)\n",
        "            del modified_word[position]\n",
        "\n",
        "    return \"\".join(modified_word)\n",
        "\n",
        "# Function to generate misspelled sentence\n",
        "def generate_misspelled_sentence(sentence, num_words_to_modify=1):\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Randomly select words to modify\n",
        "    words_to_modify = random.sample(range(len(words)), min(num_words_to_modify, len(words)))\n",
        "\n",
        "    # Generate misspelled version of the selected words\n",
        "    for i in words_to_modify:\n",
        "        words[i] = generate_misspelled_word(words[i])\n",
        "\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def letters(input):\n",
        "    return ''.join([c for c in input if c.isalpha() or c == ' '])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Function to read sentences from file\n",
        "def read_sentences_from_file(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        sentences = file.read().split('\\n')\n",
        "        sentences = [re.sub(' +', ' ', letters(s).strip().lower()) for s in sentences]\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = read_sentences_from_file(\"./data/sentences.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['they fought a deadly war',\n",
              "  'their house was farther away from my place',\n",
              "  'so i think we would not be alive if our ancestors did not develop sciences and technologies',\n",
              "  'imagine yourself you are working in factory just to do one thing like put air a on car if they fire you you will be destroyed because you do nt know more than to put air a in car',\n",
              "  'for example they can play football whenever they want but the elders can not'],\n",
              " 42)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences[:5], len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['they foght y deadly war',\n",
              " 'their holse was farther away ffom my place',\n",
              " 's i think we would not be alive hif our ancestors did not develop sciences and technologies',\n",
              " 'imagine yourself you are working in factory just po do one thing like put air a non car if they fire you you will be destroyed because you do nt know more than to put air a in car',\n",
              " 'qfor example they can play football whenever they want but thf elders can not']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mutated = [generate_misspelled_sentence(s, num_words_to_modify=2) for s in sentences]\n",
        "mutated[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['they fought a deadly war',\n",
              " 'their house was farther away from my place',\n",
              " 'so i think we would not be alive if our ancestors did not develop sciences and technologies',\n",
              " 'imagine yourself you are working in factory just to do one thing like put air a on car if they fire you you will be destroyed because you do nt know more than to put air a in car',\n",
              " 'for example they can play football whenever they want but the elders can not']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = [correct_sentence(s) for s in sentences]\n",
        "predictions[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR\n",
            "Original sentence: \t furthermore a tour guide will also provide safety and security for travel since they already know the dos and donts of the tour\n",
            "\n",
            "Prediction       : \t furthermore a tour guide will also provide safety and security for travel since they already know the dos and dots of the tour\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "for s1, s2 in zip(sentences, predictions):\n",
        "    total += 1\n",
        "    if s1 == s2:\n",
        "        correct += 1\n",
        "    else:\n",
        "        print('ERROR')\n",
        "        print(f'Original sentence: \\t {s1}')\n",
        "        print()\n",
        "        print(f'Prediction       : \\t {s2}')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final accuracy is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9761904761904762"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct / total"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
